{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "#Jets adding\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import combined data from csv\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\grovenbm\\\\Documents\\\\oms_analytics\\\\CSE 6242\\\\Project\\\\Tests\\\\philly_final_dataset_Reduced.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['sale_price']\n",
    "data_Features = data.drop(columns=['sale_price','Est TOM in Days'])\n",
    "data_hot = data_Features\n",
    "data_hot = pd.get_dummies(data_hot, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data10_hot, y, test_size=0.3, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_hot, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Standardize full feature set for Elastic Net variable selection\n",
    "scaler_full = StandardScaler()\n",
    "X_train_scaled_full = scaler_full.fit_transform(X_train)\n",
    "X_test_scaled_full = scaler_full.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:\n",
      "Index(['zip_code', 'central_air', 'garage_spaces', 'number_of_bedrooms',\n",
      "       'number_of_bathrooms', 'number_stories', 'total_livable_area',\n",
      "       'total_area', 'year_built', 'has_basements', 'active_inventory',\n",
      "       'new_listings', 'pending_sales', 'homes_sold', 'sale_to_list_ratio',\n",
      "       'percent_above_list', 'avg_days_on_market', 'avg_list_price_per_sqft',\n",
      "       'avg_listed_price', 'avg_price_per_sqft', 'avg_price_sold'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Variable selection with Elastic Net\n",
    "elasticNet = ElasticNetCV(l1_ratio=0.5, cv=5)\n",
    "elasticNet.fit(X_train_scaled_full, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "coefficients = elasticNet.coef_\n",
    "selected_features = data_hot.columns[coefficients != 0]\n",
    "print(\"Selected features:\")\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------End of Variable Selection--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------------------------End of Variable Selection--------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "[-536867.07825505   74352.83834669 1013906.94758709 ... 1887590.41706514\n",
      "  114726.50446234  964439.23253535]\n",
      "RMSE:\n",
      "959831.7116652863\n",
      "R2:\n",
      "0.2727150065364611\n",
      "Coefficients:\n",
      "[-2.54615666e+03  1.78051550e+05  2.22946209e+05  3.51178029e+04\n",
      "  9.00308543e+04  6.43461597e+05  1.27498317e+01  1.16779265e-02\n",
      " -1.36256168e+02 -3.91394065e+05  9.02889870e+02 -4.97894032e+03\n",
      "  1.03990159e+04 -5.15106133e+03 -8.17391891e+05 -7.58625667e+04\n",
      " -1.22987216e+03  4.12535581e+02  3.08817598e-01  7.33931129e+02\n",
      " -6.71925879e-01]\n",
      "Intercept:\n",
      "48756421.45380745\n"
     ]
    }
   ],
   "source": [
    "#Instiantiate model\n",
    "LMmodel = LinearRegression()\n",
    "\n",
    "#fit model to training data. Using only selected features\n",
    "X_train_selected = X_train[selected_features]\n",
    "\n",
    "LMmodel.fit(X_train_selected, y_train)\n",
    "\n",
    "#predict on test data\n",
    "x_test_selected = X_test[selected_features]\n",
    "y_pred = LMmodel.predict(x_test_selected)\n",
    "\n",
    "print(\"Predictions:\")\n",
    "print(y_pred)\n",
    "\n",
    "#calculate RMSE and R2\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\")\n",
    "print(RMSE)\n",
    "print(\"R2:\")\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "print(R2)\n",
    "\n",
    "#Access coefficients\n",
    "coefficients = LMmodel.coef_\n",
    "print(\"Coefficients:\")\n",
    "print(coefficients)\n",
    "\n",
    "#Access intercept\n",
    "intercept = LMmodel.intercept_\n",
    "print(\"Intercept:\")\n",
    "print(intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress...\n",
      "Predictions:\n",
      "[ 212970.          133028.16357143  540709.9        ... 3009170.16\n",
      "  171568.88        460658.62      ]\n",
      "RMSE:\n",
      "566252.6303970212\n",
      "R2:\n",
      "0.7468750803573763\n",
      "Feature Importances:\n",
      "total_livable_area         0.451488\n",
      "number_stories             0.284773\n",
      "total_area                 0.050796\n",
      "year_built                 0.030524\n",
      "number_of_bathrooms        0.021411\n",
      "new_listings               0.015918\n",
      "number_of_bedrooms         0.015638\n",
      "homes_sold                 0.015600\n",
      "sale_to_list_ratio         0.014730\n",
      "percent_above_list         0.010720\n",
      "pending_sales              0.010152\n",
      "central_air                0.009806\n",
      "avg_days_on_market         0.009743\n",
      "zip_code                   0.009276\n",
      "avg_list_price_per_sqft    0.008718\n",
      "avg_price_per_sqft         0.008409\n",
      "garage_spaces              0.007334\n",
      "active_inventory           0.007209\n",
      "avg_listed_price           0.006867\n",
      "off_market_2w              0.006863\n",
      "avg_price_sold             0.003926\n",
      "has_basements              0.000096\n",
      "crimes_per_100k            0.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "#Instantiating Random Forest Model\n",
    "RFmodel = RandomForestRegressor(n_estimators=50, random_state=1,n_jobs=-1 ,verbose=1)\n",
    "\n",
    "#RF model fit\n",
    "RFmodel.fit(X_train, y_train)\n",
    "\n",
    "#Sanity check\n",
    "print(\"Progress...\")\n",
    "\n",
    "#Predicting on test data\n",
    "y_pred_RF = RFmodel.predict(X_test)\n",
    "print(\"Predictions:\")\n",
    "print(y_pred_RF)\n",
    "\n",
    "# Calculate RMSE and R2\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, y_pred_RF))\n",
    "print(\"RMSE:\")\n",
    "print(RMSE)\n",
    "print(\"R2:\")\n",
    "R2 = r2_score(y_test, y_pred_RF)\n",
    "print(R2)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Access feature importances (since Random Forest models provide feature importance)\n",
    "print(\"Feature Importances:\")\n",
    "feature_importance = pd.Series(RFmodel.feature_importances_, index=feature_names)\n",
    "feature_importance = feature_importance.sort_values(ascending=False)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "[ 186185.3796489   154549.64214761  503762.22204732 ... 5896230.10965903\n",
      "  172904.81040553  532677.65280899]\n",
      "RMSE (Gradient Boosting): 588992.4623750218\n",
      "R² (Gradient Boosting): 0.7261366529106794\n",
      "Feature Importances:\n",
      "total_livable_area         0.389131\n",
      "number_stories             0.333210\n",
      "total_area                 0.058635\n",
      "number_of_bathrooms        0.042866\n",
      "zip_code                   0.037359\n",
      "year_built                 0.029705\n",
      "homes_sold                 0.023301\n",
      "garage_spaces              0.012275\n",
      "avg_listed_price           0.008337\n",
      "avg_list_price_per_sqft    0.008196\n",
      "number_of_bedrooms         0.007945\n",
      "new_listings               0.007783\n",
      "avg_price_sold             0.007647\n",
      "central_air                0.007599\n",
      "percent_above_list         0.005249\n",
      "avg_price_per_sqft         0.004902\n",
      "pending_sales              0.004603\n",
      "avg_days_on_market         0.004403\n",
      "sale_to_list_ratio         0.003445\n",
      "active_inventory           0.001797\n",
      "off_market_2w              0.001564\n",
      "has_basements              0.000049\n",
      "crimes_per_100k            0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Gradient Boosting model\n",
    "\n",
    "'''\n",
    "GBmodel = GradientBoostingRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.15,\n",
    "    max_depth=4,\n",
    "    random_state=1,\n",
    "    verbose=1\n",
    ")\n",
    "'''\n",
    "GBmodel = GradientBoostingRegressor(\n",
    "    subsample= 1.0, n_estimators= 500,\n",
    "    min_samples_split= 2, min_samples_leaf= 1,\n",
    "    max_features= None, max_depth= 4, learning_rate= 0.15\n",
    ")\n",
    "\n",
    "# Fit the model on untransformed target\n",
    "GBmodel.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_GB = GBmodel.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "RMSE_GB = np.sqrt(mean_squared_error(y_test, y_pred_GB))\n",
    "R2_GB = r2_score(y_test, y_pred_GB)\n",
    "\n",
    "print(\"Predictions:\")\n",
    "print(y_pred_GB)\n",
    "print(\"RMSE (Gradient Boosting):\", RMSE_GB)\n",
    "print(\"R² (Gradient Boosting):\", R2_GB)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Access feature importances\n",
    "print(\"Feature Importances:\")\n",
    "feature_importance = pd.Series(GBmodel.feature_importances_, index=feature_names)\n",
    "feature_importance = feature_importance.sort_values(ascending=False)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best Parameters Found:\n",
      "{'subsample': 1.0, 'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 3, 'learning_rate': 0.1}\n",
      "Best Cross-Validated R² Score:\n",
      "0.5940243816784413\n",
      "\n",
      "Test Set Evaluation\n",
      "RMSE: 686769.4148392775\n",
      "R²: 0.6276628851536792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['modelSale.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameter distribution\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Instantiate base model\n",
    "gbr = GradientBoostingRegressor(random_state=1)\n",
    "\n",
    "# Set up randomized search\n",
    "rand_search = RandomizedSearchCV(\n",
    "    estimator=gbr,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,               # Number of random combinations to try\n",
    "    scoring='r2',            # Optimize for R² score\n",
    "    cv=3,                    # 3-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1,               # Use all available cores\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit to training data\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best Parameters Found:\")\n",
    "print(rand_search.best_params_)\n",
    "print(\"Best Cross-Validated R² Score:\")\n",
    "print(rand_search.best_score_)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_gbr = rand_search.best_estimator_\n",
    "y_pred_best = best_gbr.predict(X_test)\n",
    "\n",
    "rmse_best = np.sqrt(mean_squared_error(y_test, y_pred_best))\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(\"\\nTest Set Evaluation\")\n",
    "print(\"RMSE:\", rmse_best)\n",
    "print(\"R²:\", r2_best)\n",
    "\n",
    "#with open(\"modelSale.pkl\", \"wb\") as f:\n",
    "    #import pickle\n",
    "joblib.dump(best_gbr, 'modelSale.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
