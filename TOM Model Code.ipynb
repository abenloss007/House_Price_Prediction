{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "#Jets adding\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\grovenbm\\\\Documents\\\\oms_analytics\\\\CSE 6242\\\\Project\\\\Tests\\\\philly_final_dataset_Reduced.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Est TOM in Days']\n",
    "data_Features = data.drop(columns=['Est TOM in Days','avg_days_on_market'])\n",
    "data_hot = data_Features\n",
    "data_hot = pd.get_dummies(data_hot, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data10_hot, y, test_size=0.3, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_hot, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Standardize full feature set for Elastic Net variable selection\n",
    "scaler_full = StandardScaler()\n",
    "X_train_scaled_full = scaler_full.fit_transform(X_train)\n",
    "X_test_scaled_full = scaler_full.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:\n",
      "Index(['zip_code', 'central_air', 'garage_spaces', 'number_of_bedrooms',\n",
      "       'number_of_bathrooms', 'number_stories', 'total_area', 'year_built',\n",
      "       'has_basements', 'sale_price', 'active_inventory', 'new_listings',\n",
      "       'pending_sales', 'homes_sold', 'sale_to_list_ratio',\n",
      "       'percent_above_list', 'off_market_2w', 'avg_list_price_per_sqft',\n",
      "       'avg_listed_price', 'avg_price_per_sqft', 'avg_price_sold'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Variable selection with Elastic Net\n",
    "elasticNet = ElasticNetCV(l1_ratio=0.5, cv=5)\n",
    "elasticNet.fit(X_train_scaled_full, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "coefficients = elasticNet.coef_\n",
    "selected_features = data_hot.columns[coefficients != 0]\n",
    "print(\"Selected features:\")\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------End of Variable Selection--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------------------------End of Variable Selection--------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "[53.9093813  58.76900196 84.39134968 ... 90.25603444 71.80279566\n",
      " 58.11903003]\n",
      "RMSE:\n",
      "18.18708475931443\n",
      "R2:\n",
      "0.6080361045559948\n",
      "Coefficients:\n",
      "[ 9.41091558e-02 -3.34858111e+00 -4.45267155e+00  2.27282301e-01\n",
      "  1.78376027e-01  1.25786965e+00 -1.88395056e-07 -7.88117414e-03\n",
      " -1.46508316e+00 -2.06519092e-07  2.55078783e-02 -4.14170884e-01\n",
      "  1.82207274e+00 -1.61422739e+00  2.06329177e+02 -3.42176524e+01\n",
      " -6.65862603e+01  6.41376087e-01 -1.53061081e-04 -6.56077761e-01\n",
      "  1.89371852e-04]\n",
      "Intercept:\n",
      "-1895.7381970064152\n"
     ]
    }
   ],
   "source": [
    "#Instiantiate model\n",
    "LMmodel = LinearRegression()\n",
    "\n",
    "#fit model to training data. Using only selected features\n",
    "X_train_selected = X_train[selected_features]\n",
    "\n",
    "LMmodel.fit(X_train_selected, y_train)\n",
    "\n",
    "#predict on test data\n",
    "x_test_selected = X_test[selected_features]\n",
    "y_pred = LMmodel.predict(x_test_selected)\n",
    "\n",
    "print(\"Predictions:\")\n",
    "print(y_pred)\n",
    "\n",
    "#calculate RMSE and R2\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\")\n",
    "print(RMSE)\n",
    "print(\"R2:\")\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "print(R2)\n",
    "\n",
    "#Access coefficients\n",
    "coefficients = LMmodel.coef_\n",
    "print(\"Coefficients:\")\n",
    "print(coefficients)\n",
    "\n",
    "#Access intercept\n",
    "intercept = LMmodel.intercept_\n",
    "print(\"Intercept:\")\n",
    "print(intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress...\n",
      "Predictions:\n",
      "[47. 49. 77. ... 75. 44. 51.]\n",
      "RMSE:\n",
      "0.5072968887479335\n",
      "R2:\n",
      "0.9996950390153779\n",
      "Feature Importances:\n",
      "homes_sold                 0.433863\n",
      "pending_sales              0.256126\n",
      "off_market_2w              0.096378\n",
      "total_area                 0.075603\n",
      "avg_price_per_sqft         0.036229\n",
      "new_listings               0.025956\n",
      "active_inventory           0.024417\n",
      "sale_to_list_ratio         0.018355\n",
      "zip_code                   0.016648\n",
      "percent_above_list         0.004721\n",
      "avg_list_price_per_sqft    0.004582\n",
      "avg_price_sold             0.003845\n",
      "avg_listed_price           0.002197\n",
      "total_livable_area         0.000352\n",
      "sale_price                 0.000205\n",
      "garage_spaces              0.000188\n",
      "number_of_bedrooms         0.000090\n",
      "number_stories             0.000087\n",
      "number_of_bathrooms        0.000074\n",
      "year_built                 0.000062\n",
      "has_basements              0.000020\n",
      "central_air                0.000001\n",
      "crimes_per_100k            0.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "#Instantiating Random Forest Model\n",
    "RFmodel = RandomForestRegressor(n_estimators=50, random_state=1,n_jobs=-1 ,verbose=1)\n",
    "\n",
    "#RF model fit\n",
    "RFmodel.fit(X_train, y_train)\n",
    "\n",
    "#Sanity check\n",
    "print(\"Progress...\")\n",
    "\n",
    "#Predicting on test data\n",
    "y_pred_RF = RFmodel.predict(X_test)\n",
    "print(\"Predictions:\")\n",
    "print(y_pred_RF)\n",
    "\n",
    "# Calculate RMSE and R2\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, y_pred_RF))\n",
    "print(\"RMSE:\")\n",
    "print(RMSE)\n",
    "print(\"R2:\")\n",
    "R2 = r2_score(y_test, y_pred_RF)\n",
    "print(R2)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Access feature importances (since Random Forest models provide feature importance)\n",
    "print(\"Feature Importances:\")\n",
    "feature_importance = pd.Series(RFmodel.feature_importances_, index=feature_names)\n",
    "feature_importance = feature_importance.sort_values(ascending=False)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "[47.00040987 48.99981465 76.9989088  ... 75.0150646  43.99524791\n",
      " 50.99968018]\n",
      "RMSE (Gradient Boosting): 0.15558822609490097\n",
      "RÂ² (Gradient Boosting): 0.9999713137788496\n",
      "Feature Importances:\n",
      "homes_sold                 4.171028e-01\n",
      "pending_sales              2.660415e-01\n",
      "off_market_2w              1.113432e-01\n",
      "total_area                 5.162176e-02\n",
      "active_inventory           4.107912e-02\n",
      "avg_price_per_sqft         3.429181e-02\n",
      "sale_to_list_ratio         1.792192e-02\n",
      "percent_above_list         1.141453e-02\n",
      "avg_price_sold             1.101152e-02\n",
      "zip_code                   1.013762e-02\n",
      "avg_listed_price           9.477905e-03\n",
      "avg_list_price_per_sqft    8.844905e-03\n",
      "new_listings               7.590357e-03\n",
      "total_livable_area         1.052193e-03\n",
      "garage_spaces              7.377014e-04\n",
      "year_built                 1.996220e-04\n",
      "sale_price                 1.105198e-04\n",
      "number_stories             1.976533e-05\n",
      "number_of_bedrooms         8.065449e-07\n",
      "number_of_bathrooms        4.428279e-07\n",
      "has_basements              4.398882e-08\n",
      "central_air                5.248093e-09\n",
      "crimes_per_100k            0.000000e+00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Gradient Boosting model\n",
    "\n",
    "'''\n",
    "GBmodel = GradientBoostingRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.15,\n",
    "    max_depth=4,\n",
    "    random_state=1,\n",
    "    verbose=1\n",
    ")\n",
    "'''\n",
    "GBmodel = GradientBoostingRegressor(\n",
    "    subsample= 1.0, n_estimators= 500,\n",
    "    min_samples_split= 2, min_samples_leaf= 1,\n",
    "    max_features= None, max_depth= 4, learning_rate= 0.15\n",
    ")\n",
    "\n",
    "# Fit the model on untransformed target\n",
    "GBmodel.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_GB = GBmodel.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "RMSE_GB = np.sqrt(mean_squared_error(y_test, y_pred_GB))\n",
    "R2_GB = r2_score(y_test, y_pred_GB)\n",
    "\n",
    "print(\"Predictions:\")\n",
    "print(y_pred_GB)\n",
    "print(\"RMSE (Gradient Boosting):\", RMSE_GB)\n",
    "print(\"RÂ² (Gradient Boosting):\", R2_GB)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Access feature importances\n",
    "print(\"Feature Importances:\")\n",
    "feature_importance = pd.Series(GBmodel.feature_importances_, index=feature_names)\n",
    "feature_importance = feature_importance.sort_values(ascending=False)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    }
   ],
   "source": [
    "# Define parameter distribution\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Instantiate base model\n",
    "gbr = GradientBoostingRegressor(random_state=1)\n",
    "\n",
    "# Set up randomized search\n",
    "rand_search = RandomizedSearchCV(\n",
    "    estimator=gbr,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,               # Number of random combinations to try\n",
    "    scoring='r2',            # Optimize for RÂ² score\n",
    "    cv=3,                    # 3-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1,               # Use all available cores\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit to training data\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best Parameters Found:\")\n",
    "print(rand_search.best_params_)\n",
    "print(\"Best Cross-Validated RÂ² Score:\")\n",
    "print(rand_search.best_score_)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_gbr = rand_search.best_estimator_\n",
    "y_pred_best = best_gbr.predict(X_test)\n",
    "\n",
    "rmse_best = np.sqrt(mean_squared_error(y_test, y_pred_best))\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(\"\\nTest Set Evaluation\")\n",
    "print(\"RMSE:\", rmse_best)\n",
    "print(\"RÂ²:\", r2_best)\n",
    "\n",
    "#with open(\"modelTOM.pkl\", \"wb\") as f:\n",
    "    #import pickle\n",
    "joblib.dump(best_gbr, 'modelTOM.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
