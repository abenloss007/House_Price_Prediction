{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "#Jets adding\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import combined data from csv\n",
    "#data = pd.read_csv(\"E:\\\\6242Project\\\\FeaturesDataset\\\\philly_property_data.csv\")\n",
    "#data = pd.read_csv(\"E:\\\\6242Project\\\\FeaturesDataset\\\\washington_property_data.csv\")\n",
    "#data = pd.read_csv(\"E:\\\\6242Project\\\\FeaturesDataset\\\\philly_enriched.csv\")\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\easto\\\\OneDrive\\\\Desktop\\\\College\\\\Masters\\\\Semester 2\\\\Data and Visual Analytics\\\\Local Project Data\\\\philly_final_dataset.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['sale_price']\n",
    "data_Features = data.drop(columns=['market_value', 'sale_price'])\n",
    "#data_hot = data_Features.drop(columns=['sale_date'])\n",
    "#data_hot = data_Features.drop(columns=['sale_date','view_scale','heater_scale','central_air','garage_spaces','has_central_air', 'has_type_heater'])\n",
    "data_hot = data_Features\n",
    "data_hot = pd.get_dummies(data_hot, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data10_hot, y, test_size=0.3, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_hot, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Standardize full feature set for Elastic Net variable selection\n",
    "scaler_full = StandardScaler()\n",
    "X_train_scaled_full = scaler_full.fit_transform(X_train)\n",
    "X_test_scaled_full = scaler_full.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:\n",
      "Index(['zip_code', 'view_scale', 'heater_scale', 'exterior_condition',\n",
      "       'interior_condition', 'central_air', 'basement_scale', 'garage_spaces',\n",
      "       'number_of_bedrooms', 'number_of_bathrooms', 'number_stories',\n",
      "       'total_livable_area', 'total_area', 'year_built', 'year_built_estimate',\n",
      "       'has_basements', 'has_central_air', 'has_type_heater',\n",
      "       'is_nominal_sale', 'market_value', 'active_inventory', 'new_listings',\n",
      "       'pending_sales', 'homes_sold', 'sale_to_list_ratio',\n",
      "       'percent_above_list', 'avg_days_on_market', 'crimes_per_100k',\n",
      "       'avg_list_price_per_sqft', 'avg_listed_price', 'avg_price_per_sqft',\n",
      "       'avg_price_sold', 'sale_day', 'sale_month', 'sale_year', 'est_list_day',\n",
      "       'est_list_month', 'est_list_year', 'Est TOM in Days'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Variable selection with Elastic Net\n",
    "elasticNet = ElasticNetCV(l1_ratio=0.5, cv=5)\n",
    "elasticNet.fit(X_train_scaled_full, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "coefficients = elasticNet.coef_\n",
    "selected_features = data_hot.columns[coefficients != 0]\n",
    "print(\"Selected features:\")\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------End of Variable Selection--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------------------------End of Variable Selection--------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "[ -23073.625  255150.125  605125.25  ... 1741806.875  128866.25\n",
      "  692749.625]\n",
      "RMSE:\n",
      "845813.8344271103\n",
      "R2:\n",
      "0.4352398999560986\n",
      "Coefficients:\n",
      "[-7.32648937e+02 -3.97354940e+03 -4.16405744e+03 -2.87525640e+02\n",
      "  6.24255807e+03  1.24663945e+05  1.67568692e+04  9.94961220e+04\n",
      "  3.83111971e+04  6.63530609e+04  3.16460987e+05  6.56967124e+00\n",
      "  6.77661602e-03 -2.84602114e+02  1.91866641e+04 -3.15411004e+05\n",
      " -5.32375422e+03 -1.32327266e+05 -2.98814859e+04  4.26624565e-01\n",
      " -2.32907283e+03  3.21438582e+03  9.39739345e+03 -1.10656171e+04\n",
      " -3.69432030e+05  1.79934865e+04 -1.10128523e+04 -1.12484842e+11\n",
      " -5.23769281e+02  3.19405469e-01  1.17831697e+03 -3.84833731e-01\n",
      "  1.42888089e+04  1.60775436e+03  1.67309291e+04 -1.05421756e+04\n",
      "  2.03354624e+03 -1.28212393e+04  3.12975465e+05]\n",
      "Intercept:\n",
      "614359763828335.9\n"
     ]
    }
   ],
   "source": [
    "#Instiantiate model\n",
    "LMmodel = LinearRegression()\n",
    "\n",
    "#fit model to training data. Using only selected features\n",
    "X_train_selected = X_train[selected_features]\n",
    "\n",
    "LMmodel.fit(X_train_selected, y_train)\n",
    "\n",
    "#predict on test data\n",
    "x_test_selected = X_test[selected_features]\n",
    "y_pred = LMmodel.predict(x_test_selected)\n",
    "\n",
    "print(\"Predictions:\")\n",
    "print(y_pred)\n",
    "\n",
    "#calculate RMSE and R2\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\")\n",
    "print(RMSE)\n",
    "print(\"R2:\")\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "print(R2)\n",
    "\n",
    "#Access coefficients\n",
    "coefficients = LMmodel.coef_\n",
    "print(\"Coefficients:\")\n",
    "print(coefficients)\n",
    "\n",
    "#Access intercept\n",
    "intercept = LMmodel.intercept_\n",
    "print(\"Intercept:\")\n",
    "print(intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress...\n",
      "Predictions:\n",
      "[2609695.66  101299.1   355752.02 ... 2299788.12  192269.96  534931.74]\n",
      "RMSE:\n",
      "651848.9288046993\n",
      "R2:\n",
      "0.6645650198347236\n",
      "Feature Importances:\n",
      "[1.23824257e-02 9.12286307e-04 2.26538061e-03 5.78246598e-04\n",
      " 5.33576108e-04 2.04984943e-04 1.03115028e-03 3.17492949e-03\n",
      " 2.28225747e-02 1.07923450e-02 1.72321512e-01 1.42507552e-01\n",
      " 1.34982167e-02 2.64347427e-02 2.12343039e-04 3.18755905e-05\n",
      " 2.40119466e-04 6.12760944e-04 3.90099477e-03 4.52127389e-01\n",
      " 6.62610428e-03 6.08785903e-03 1.50710429e-02 1.53812411e-03\n",
      " 6.18518245e-03 6.63041808e-03 3.03163050e-03 0.00000000e+00\n",
      " 6.48057333e-03 5.92648625e-03 5.65452567e-03 2.43301318e-03\n",
      " 2.92338662e-03 2.18813404e-02 2.68427391e-02 1.26971922e-04\n",
      " 4.23777145e-03 9.10765179e-03 2.04252180e-03 5.87251288e-04]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "#Instantiating Random Forest Model\n",
    "RFmodel = RandomForestRegressor(n_estimators=50, random_state=1,n_jobs=-1 ,verbose=1)\n",
    "\n",
    "#RF model fit\n",
    "RFmodel.fit(X_train, y_train)\n",
    "\n",
    "#Sanity check\n",
    "print(\"Progress...\")\n",
    "\n",
    "#Predicting on test data\n",
    "y_pred_RF = RFmodel.predict(X_test)\n",
    "print(\"Predictions:\")\n",
    "print(y_pred_RF)\n",
    "\n",
    "# Calculate RMSE and R2\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, y_pred_RF))\n",
    "print(\"RMSE:\")\n",
    "print(RMSE)\n",
    "print(\"R2:\")\n",
    "R2 = r2_score(y_test, y_pred_RF)\n",
    "print(R2)\n",
    "\n",
    "# Access feature importances (since Random Forest models provide feature importance)\n",
    "feature_importances = RFmodel.feature_importances_\n",
    "print(\"Feature Importances:\")\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "[1908489.28057221   90702.66985398  391082.66783975 ... 2081460.45358845\n",
      "  184379.51783614  453965.32259484]\n",
      "RMSE (Gradient Boosting): 690812.7493570889\n",
      "R² (Gradient Boosting): 0.6232657316963437\n",
      "Feature Importances (Gradient Boosting):\n",
      "[1.84606240e-02 1.70624092e-04 1.38825407e-03 2.78793858e-04\n",
      " 6.22624546e-04 2.34726385e-03 1.57167486e-04 1.38438353e-03\n",
      " 6.12629551e-02 1.78957787e-02 1.52909853e-01 7.84399568e-02\n",
      " 1.45357349e-02 1.11634125e-02 1.17502304e-04 2.61749205e-05\n",
      " 6.20522124e-04 8.79335800e-04 3.94719311e-03 5.44584571e-01\n",
      " 1.44482018e-02 3.14957108e-03 3.46868591e-04 5.86768818e-04\n",
      " 2.02696156e-03 1.07130176e-02 1.42071678e-03 0.00000000e+00\n",
      " 2.92711088e-03 2.92173908e-03 9.35105594e-04 1.10331293e-03\n",
      " 1.66706206e-03 1.44941692e-02 2.00757096e-02 8.40941417e-05\n",
      " 2.78497092e-03 8.19704265e-03 5.06989162e-04 4.17861743e-04]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Gradient Boosting model\n",
    "\n",
    "'''\n",
    "GBmodel = GradientBoostingRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.15,\n",
    "    max_depth=4,\n",
    "    random_state=1,\n",
    "    verbose=1\n",
    ")\n",
    "'''\n",
    "GBmodel = GradientBoostingRegressor(\n",
    "    subsample= 1.0, n_estimators= 500,\n",
    "    min_samples_split= 2, min_samples_leaf= 1,\n",
    "    max_features= None, max_depth= 4, learning_rate= 0.15\n",
    ")\n",
    "\n",
    "# Fit the model on untransformed target\n",
    "GBmodel.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_GB = GBmodel.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "RMSE_GB = np.sqrt(mean_squared_error(y_test, y_pred_GB))\n",
    "R2_GB = r2_score(y_test, y_pred_GB)\n",
    "\n",
    "print(\"Predictions:\")\n",
    "print(y_pred_GB)\n",
    "print(\"RMSE (Gradient Boosting):\", RMSE_GB)\n",
    "print(\"R² (Gradient Boosting):\", R2_GB)\n",
    "\n",
    "# Access feature importances\n",
    "feature_importances_GB = GBmodel.feature_importances_\n",
    "print(\"Feature Importances (Gradient Boosting):\")\n",
    "print(feature_importances_GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best Parameters Found:\n",
      "{'subsample': 1.0, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 5, 'learning_rate': 0.05}\n",
      "Best Cross-Validated R² Score:\n",
      "0.6027468648304829\n",
      "\n",
      "Test Set Evaluation\n",
      "RMSE: 669651.287924494\n",
      "R²: 0.6459929959238864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['modelSale.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameter distribution\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Instantiate base model\n",
    "gbr = GradientBoostingRegressor(random_state=1)\n",
    "\n",
    "# Set up randomized search\n",
    "rand_search = RandomizedSearchCV(\n",
    "    estimator=gbr,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,               # Number of random combinations to try\n",
    "    scoring='r2',            # Optimize for R² score\n",
    "    cv=3,                    # 3-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1,               # Use all available cores\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit to training data\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best Parameters Found:\")\n",
    "print(rand_search.best_params_)\n",
    "print(\"Best Cross-Validated R² Score:\")\n",
    "print(rand_search.best_score_)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_gbr = rand_search.best_estimator_\n",
    "y_pred_best = best_gbr.predict(X_test)\n",
    "\n",
    "rmse_best = np.sqrt(mean_squared_error(y_test, y_pred_best))\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(\"\\nTest Set Evaluation\")\n",
    "print(\"RMSE:\", rmse_best)\n",
    "print(\"R²:\", r2_best)\n",
    "\n",
    "#with open(\"modelSale.pkl\", \"wb\") as f:\n",
    "    #import pickle\n",
    "joblib.dump(best_gbr, 'modelSale.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
