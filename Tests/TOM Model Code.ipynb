{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "#Jets adding\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\grovenbm\\\\Documents\\\\oms_analytics\\\\CSE 6242\\\\Project\\\\Tests\\\\philly_final_dataset_Reduced.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Est TOM in Days']\n",
    "data_Features = data.drop(columns=['Est TOM in Days','sale_month','sale_year','sale_day','avg_days_on_market'])\n",
    "#data_hot = data_Features.drop(columns=['sale_date'])\n",
    "#data_hot = data_Features.drop(columns=['sale_date','view_scale','heater_scale','central_air','garage_spaces','has_central_air', 'has_type_heater'])\n",
    "data_hot = data_Features\n",
    "data_hot = pd.get_dummies(data_hot, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data10_hot, y, test_size=0.3, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_hot, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Standardize full feature set for Elastic Net variable selection\n",
    "scaler_full = StandardScaler()\n",
    "X_train_scaled_full = scaler_full.fit_transform(X_train)\n",
    "X_test_scaled_full = scaler_full.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:\n",
      "Index(['zip_code', 'central_air', 'garage_spaces', 'number_of_bedrooms',\n",
      "       'number_of_bathrooms', 'number_stories', 'total_area', 'year_built',\n",
      "       'has_basements', 'sale_price', 'active_inventory', 'new_listings',\n",
      "       'pending_sales', 'homes_sold', 'sale_to_list_ratio',\n",
      "       'percent_above_list', 'off_market_2w', 'avg_list_price_per_sqft',\n",
      "       'avg_listed_price', 'avg_price_per_sqft', 'avg_price_sold',\n",
      "       'est_list_day', 'est_list_month', 'est_list_year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Variable selection with Elastic Net\n",
    "elasticNet = ElasticNetCV(l1_ratio=0.5, cv=5)\n",
    "elasticNet.fit(X_train_scaled_full, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "coefficients = elasticNet.coef_\n",
    "selected_features = data_hot.columns[coefficients != 0]\n",
    "print(\"Selected features:\")\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------End of Variable Selection--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------------------------End of Variable Selection--------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "[53.76149549 58.4696186  84.53251872 ... 89.78126251 71.23851616\n",
      " 57.45903742]\n",
      "RMSE:\n",
      "18.178997087083324\n",
      "R2:\n",
      "0.6083846343725399\n",
      "Coefficients:\n",
      "[ 9.41888976e-02 -3.29327978e+00 -4.45163537e+00  2.38468786e-01\n",
      "  1.51073892e-01  1.24835574e+00 -1.81235008e-07 -7.90761991e-03\n",
      " -1.54455485e+00 -2.02090748e-07  2.38223279e-02 -4.09704070e-01\n",
      "  1.81506501e+00 -1.60990737e+00  2.05525965e+02 -3.38799962e+01\n",
      " -6.62717889e+01  6.40060266e-01 -1.52874283e-04 -6.54656112e-01\n",
      "  1.89248753e-04  2.16153174e-02 -4.48922836e-02 -9.18963715e-01]\n",
      "Intercept:\n",
      "-36.80347273832796\n"
     ]
    }
   ],
   "source": [
    "#Instiantiate model\n",
    "LMmodel = LinearRegression()\n",
    "\n",
    "#fit model to training data. Using only selected features\n",
    "X_train_selected = X_train[selected_features]\n",
    "\n",
    "LMmodel.fit(X_train_selected, y_train)\n",
    "\n",
    "#predict on test data\n",
    "x_test_selected = X_test[selected_features]\n",
    "y_pred = LMmodel.predict(x_test_selected)\n",
    "\n",
    "print(\"Predictions:\")\n",
    "print(y_pred)\n",
    "\n",
    "#calculate RMSE and R2\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\")\n",
    "print(RMSE)\n",
    "print(\"R2:\")\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "print(R2)\n",
    "\n",
    "#Access coefficients\n",
    "coefficients = LMmodel.coef_\n",
    "print(\"Coefficients:\")\n",
    "print(coefficients)\n",
    "\n",
    "#Access intercept\n",
    "intercept = LMmodel.intercept_\n",
    "print(\"Intercept:\")\n",
    "print(intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress...\n",
      "Predictions:\n",
      "[47. 49. 77. ... 75. 44. 51.]\n",
      "RMSE:\n",
      "0.46487353118886\n",
      "R2:\n",
      "0.9997439118269166\n",
      "Feature Importances:\n",
      "homes_sold                 4.313126e-01\n",
      "pending_sales              2.592098e-01\n",
      "off_market_2w              9.668440e-02\n",
      "total_area                 7.563232e-02\n",
      "avg_price_per_sqft         3.609260e-02\n",
      "new_listings               2.672659e-02\n",
      "active_inventory           2.443354e-02\n",
      "sale_to_list_ratio         1.771693e-02\n",
      "zip_code                   1.582019e-02\n",
      "percent_above_list         4.929447e-03\n",
      "avg_list_price_per_sqft    4.578693e-03\n",
      "avg_price_sold             3.214244e-03\n",
      "avg_listed_price           2.402260e-03\n",
      "total_livable_area         4.635287e-04\n",
      "sale_price                 3.861664e-04\n",
      "garage_spaces              1.186393e-04\n",
      "number_stories             9.877637e-05\n",
      "number_of_bathrooms        8.095813e-05\n",
      "number_of_bedrooms         7.459844e-05\n",
      "has_basements              1.745431e-05\n",
      "est_list_month             3.954511e-06\n",
      "est_list_year              1.907058e-06\n",
      "year_built                 3.476579e-07\n",
      "central_air                0.000000e+00\n",
      "crimes_per_100k            0.000000e+00\n",
      "est_list_day               0.000000e+00\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "#Instantiating Random Forest Model\n",
    "RFmodel = RandomForestRegressor(n_estimators=50, random_state=1,n_jobs=-1 ,verbose=1)\n",
    "\n",
    "#RF model fit\n",
    "RFmodel.fit(X_train, y_train)\n",
    "\n",
    "#Sanity check\n",
    "print(\"Progress...\")\n",
    "\n",
    "#Predicting on test data\n",
    "y_pred_RF = RFmodel.predict(X_test)\n",
    "print(\"Predictions:\")\n",
    "print(y_pred_RF)\n",
    "\n",
    "# Calculate RMSE and R2\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, y_pred_RF))\n",
    "print(\"RMSE:\")\n",
    "print(RMSE)\n",
    "print(\"R2:\")\n",
    "R2 = r2_score(y_test, y_pred_RF)\n",
    "print(R2)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Access feature importances (since Random Forest models provide feature importance)\n",
    "print(\"Feature Importances:\")\n",
    "feature_importance = pd.Series(RFmodel.feature_importances_, index=feature_names)\n",
    "feature_importance = feature_importance.sort_values(ascending=False)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "[46.99875657 49.00089814 76.99705144 ... 74.9935384  44.00393308\n",
      " 51.00273766]\n",
      "RMSE (Gradient Boosting): 0.17432797963024993\n",
      "R² (Gradient Boosting): 0.9999639874331515\n",
      "Feature Importances (Gradient Boosting):\n",
      "[9.99267049e-03 1.70170130e-08 5.52535178e-04 1.26403452e-07\n",
      " 1.25149522e-07 1.42440193e-06 1.31428061e-03 5.19193725e-02\n",
      " 2.00653370e-04 6.86740669e-11 1.95089159e-06 4.15696403e-02\n",
      " 8.54679204e-03 2.65114109e-01 4.15315991e-01 1.82077335e-02\n",
      " 1.05356449e-02 0.00000000e+00 1.12790986e-01 9.74461276e-03\n",
      " 1.08293153e-02 3.46732474e-02 8.67329763e-03 2.99676831e-08\n",
      " 1.37646791e-06 1.40670927e-05]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Gradient Boosting model\n",
    "\n",
    "'''\n",
    "GBmodel = GradientBoostingRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.15,\n",
    "    max_depth=4,\n",
    "    random_state=1,\n",
    "    verbose=1\n",
    ")\n",
    "'''\n",
    "GBmodel = GradientBoostingRegressor(\n",
    "    subsample= 1.0, n_estimators= 500,\n",
    "    min_samples_split= 2, min_samples_leaf= 1,\n",
    "    max_features= None, max_depth= 4, learning_rate= 0.15\n",
    ")\n",
    "\n",
    "# Fit the model on untransformed target\n",
    "GBmodel.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_GB = GBmodel.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "RMSE_GB = np.sqrt(mean_squared_error(y_test, y_pred_GB))\n",
    "R2_GB = r2_score(y_test, y_pred_GB)\n",
    "\n",
    "print(\"Predictions:\")\n",
    "print(y_pred_GB)\n",
    "print(\"RMSE (Gradient Boosting):\", RMSE_GB)\n",
    "print(\"R² (Gradient Boosting):\", R2_GB)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Access feature importances\n",
    "print(\"Feature Importances:\")\n",
    "feature_importance = pd.Series(GBmodel.feature_importances_, index=feature_names)\n",
    "feature_importance = feature_importance.sort_values(ascending=False)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best Parameters Found:\n",
      "{'subsample': 1.0, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 3, 'learning_rate': 0.15}\n",
      "Best Cross-Validated R² Score:\n",
      "0.9967867275527623\n",
      "\n",
      "Test Set Evaluation\n",
      "RMSE: 0.4844899987014061\n",
      "R²: 0.9997218433057793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['modelTOM.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameter distribution\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Instantiate base model\n",
    "gbr = GradientBoostingRegressor(random_state=1)\n",
    "\n",
    "# Set up randomized search\n",
    "rand_search = RandomizedSearchCV(\n",
    "    estimator=gbr,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,               # Number of random combinations to try\n",
    "    scoring='r2',            # Optimize for R² score\n",
    "    cv=3,                    # 3-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1,               # Use all available cores\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit to training data\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best Parameters Found:\")\n",
    "print(rand_search.best_params_)\n",
    "print(\"Best Cross-Validated R² Score:\")\n",
    "print(rand_search.best_score_)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_gbr = rand_search.best_estimator_\n",
    "y_pred_best = best_gbr.predict(X_test)\n",
    "\n",
    "rmse_best = np.sqrt(mean_squared_error(y_test, y_pred_best))\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(\"\\nTest Set Evaluation\")\n",
    "print(\"RMSE:\", rmse_best)\n",
    "print(\"R²:\", r2_best)\n",
    "\n",
    "#with open(\"modelTOM.pkl\", \"wb\") as f:\n",
    "    #import pickle\n",
    "joblib.dump(best_gbr, 'modelTOM.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
