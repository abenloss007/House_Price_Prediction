{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Open Data From City of Philadelphia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Dataset From https://cityofphiladelphia.github.io/carto-api-explorer/#opa_properties_public"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The website's features for predicting the cost of homes should include:\n",
    "- **Select**: city, state, zip_code, property_type\n",
    "- **Values**: square_ft/ acers, *number_of_bedrooms, number_of_rooms, spaces_in_garage, number_of_floors, etc*\n",
    "- **Bools**: *pool, basement, fence, lake, etc.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_philly_data(limit, max_records):\n",
    "    all_data = []\n",
    "    for offset in range(0, max_records, limit):\n",
    "        # limit amount of data requested from api, offset to read new data\n",
    "        sql = f\"SELECT * FROM opa_properties_public LIMIT {limit} OFFSET {offset}\"\n",
    "        url = f\"https://phl.carto.com/api/v2/sql?q={sql}\"\n",
    "        resp = requests.get(url)\n",
    "        # check for error in fetching data\n",
    "        if resp.status_code != 200:\n",
    "            print(f\"Error fetching offset {offset}\")\n",
    "            break\n",
    "        # avoid empty chunks of data in api\n",
    "        chunk = resp.json().get('rows', [])\n",
    "        if not chunk:\n",
    "            break\n",
    "        # combine all chunks of data\n",
    "        all_data.extend(chunk)\n",
    "        #print(f\"fetched {len(chunk)} records at offset = {offset}\")\n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "# fetch data from open source\n",
    "df = fetch_philly_data(limit=1000, max_records=20000)\n",
    "\n",
    "# check the structure of the dataframe\n",
    "#df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep columns where at least 25% of values are non-null\n",
    "threshold = len(df) * 0.25\n",
    "df = df.dropna(axis=1, thresh=threshold)\n",
    "# drop all rows where 'zip_code' is missing\n",
    "df = df.dropna(subset=['zip_code'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# check the structure of the dataframe\n",
    "#df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select and keep features that users will have access to and any key features\n",
    "columns_to_keep = [\n",
    "    'zip_code',\n",
    "    'total_livable_area',\n",
    "    'total_area',\n",
    "    'number_of_bedrooms',\n",
    "    'number_of_bathrooms',\n",
    "    'number_stories',\n",
    "    'garage_spaces',\n",
    "    'basements',\n",
    "    'view_type',\n",
    "    'central_air',\n",
    "    'type_heater',\n",
    "    'exterior_condition',\n",
    "    'interior_condition',\n",
    "    'sale_price',\n",
    "    'sale_date',\n",
    "    'market_value',\n",
    "    'year_built',\n",
    "    'year_built_estimate'\n",
    "]\n",
    "\n",
    "df_model = df[columns_to_keep].copy()\n",
    "\n",
    "# check the structure of the dataframe\n",
    "#df_model.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create flags for columns with < 75% non-null values\n",
    "# define columns to exclude that can't be included\n",
    "exclude_cols = ['year_built', 'year_built_estimate']\n",
    "\n",
    "for col in df_model.columns:\n",
    "    if col not in exclude_cols and df_model[col].notna().mean() < 0.75:\n",
    "        df_model[f'has_{col}'] = df_model[col].notna()\n",
    "        \n",
    "# check the structure of the dataframe\n",
    "#df_model.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data exists where sale_price is 1 or 0\n",
    "# create flag where sale_prices are unreasonably low as a nominal sale\n",
    "\n",
    "df_model['is_nominal_sale'] = df_model['sale_price'] <= 1000\n",
    "df_model.loc[df_model['is_nominal_sale'], 'sale_price'] = pd.NA\n",
    "\n",
    "# finish creating flags for year_built estimates,\n",
    "df_model['year_built_estimate'] = df_model['year_built_estimate'].isna()\n",
    "df_model['year_built_estimate'] = df_model['year_built_estimate'].astype(bool)\n",
    "\n",
    "#df_model.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19998 entries, 0 to 19997\n",
      "Data columns (total 22 columns):\n",
      " #   Column               Non-Null Count  Dtype              \n",
      "---  ------               --------------  -----              \n",
      " 0   zip_code             19998 non-null  object             \n",
      " 1   total_livable_area   19045 non-null  float64            \n",
      " 2   total_area           19995 non-null  float64            \n",
      " 3   number_of_bedrooms   18037 non-null  Int64              \n",
      " 4   number_of_bathrooms  17764 non-null  Int64              \n",
      " 5   number_stories       18269 non-null  Int64              \n",
      " 6   garage_spaces        17779 non-null  Int64              \n",
      " 7   basements            13210 non-null  category           \n",
      " 8   view_type            19496 non-null  category           \n",
      " 9   central_air          12526 non-null  category           \n",
      " 10  type_heater          13124 non-null  category           \n",
      " 11  exterior_condition   19041 non-null  category           \n",
      " 12  interior_condition   19041 non-null  category           \n",
      " 13  sale_price           15308 non-null  Int64              \n",
      " 14  sale_date            19998 non-null  datetime64[ns, UTC]\n",
      " 15  market_value         19998 non-null  float64            \n",
      " 16  year_built           19045 non-null  Int64              \n",
      " 17  year_built_estimate  19998 non-null  category           \n",
      " 18  has_basements        19998 non-null  bool               \n",
      " 19  has_central_air      19998 non-null  bool               \n",
      " 20  has_type_heater      19998 non-null  bool               \n",
      " 21  is_nominal_sale      19998 non-null  bool               \n",
      "dtypes: Int64(6), bool(4), category(7), datetime64[ns, UTC](1), float64(3), object(1)\n",
      "memory usage: 3.0 MB\n"
     ]
    }
   ],
   "source": [
    "# zip_code to string avoiding any leading zeros\n",
    "df_model['zip_code'] = df_model['zip_code'].astype(str)\n",
    "\n",
    "# convert numeric features to integers\n",
    "int_cols = [\n",
    "    'number_of_bedrooms',\n",
    "    'number_of_bathrooms',\n",
    "    'number_stories',\n",
    "    'garage_spaces',\n",
    "    'year_built', \n",
    "]\n",
    "\n",
    "for col in int_cols:\n",
    "    df_model[col] = pd.to_numeric(df_model[col], errors='coerce').astype('Int64')\n",
    "\n",
    "# sale_price should be float or int — it’s currently object due to NaNs or strings\n",
    "df_model['sale_price'] = pd.to_numeric(df_model['sale_price'], errors='coerce').astype('Int64')\n",
    "\n",
    "# keep total_livable_area, total_area, and market_value as float\n",
    "df_model['total_livable_area'] = pd.to_numeric(df_model['total_livable_area'], errors='coerce').astype(float)\n",
    "df_model['total_area'] = pd.to_numeric(df_model['total_area'], errors='coerce').astype(float)\n",
    "df_model['market_value'] = pd.to_numeric(df_model['market_value'], errors='coerce').astype(float)\n",
    "\n",
    "# dates\n",
    "df_model['sale_date'] = pd.to_datetime(df_model['sale_date'], errors='coerce')\n",
    "\n",
    "# Strings (categorical or object-type)\n",
    "cat_cols = [\n",
    "    'basements', 'view_type', 'central_air',\n",
    "    'type_heater', 'exterior_condition', 'interior_condition',\n",
    "    'year_built_estimate'\n",
    "]\n",
    "\n",
    "for col in cat_cols:\n",
    "    df_model[col] = df_model[col].astype('category')\n",
    "\n",
    "df_model.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled 3 rows in total_area\n",
      "Filled 953 rows in total_livable_area\n",
      "Filled 953 rows in year_built\n",
      "Filled 1729 rows in number_stories\n",
      "Filled 1961 rows in number_of_bedrooms\n",
      "Filled 2219 rows in garage_spaces\n",
      "Filled 2234 rows in number_of_bathrooms\n",
      "Filled 4690 rows in sale_price\n"
     ]
    }
   ],
   "source": [
    "# now we want to fill in data using histogram based gradient boosting\n",
    "# make a copy to preserve original\n",
    "df_filled = df_model.copy()\n",
    "# convert 'sale_date' into their own features to use learning models\n",
    "df_filled['sale_date'] = pd.to_datetime(df_filled['sale_date'], errors='coerce')\n",
    "df_filled['sale_year'] = df_filled['sale_date'].dt.year\n",
    "df_filled['sale_month'] = df_filled['sale_date'].dt.month\n",
    "df_filled['sale_day'] = df_filled['sale_date'].dt.day\n",
    "\n",
    "# remove sale_date to avoid errors in model\n",
    "df_filled = df_filled.drop(columns=['sale_date'])\n",
    "# sum the missing values in each column\n",
    "numeric_cols_to_fill = [\n",
    "    col for col in df_filled.columns\n",
    "    if df_filled[col].isna().sum() > 0 and pd.api.types.is_numeric_dtype(df_filled[col])\n",
    "]\n",
    "\n",
    "# sort by fewest missing values first\n",
    "numeric_cols_to_fill = sorted(numeric_cols_to_fill, key=lambda c: df_filled[c].isna().sum())\n",
    "\n",
    "# ordinal encode any categorical variables for modeling\n",
    "categorical_cols = df_filled.select_dtypes(['category']).columns\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "df_filled[categorical_cols] = encoder.fit_transform(df_filled[categorical_cols].astype(str))\n",
    "\n",
    "# impute one column at a time\n",
    "for col in numeric_cols_to_fill:\n",
    "    not_null = df_filled[df_filled[col].notna()]\n",
    "    is_null = df_filled[df_filled[col].isna()]\n",
    "    \n",
    "    if not_null.shape[0] < 100:\n",
    "        print(f\"Skipping {col} (too few non-null rows)\")\n",
    "        continue\n",
    "\n",
    "    features = df_filled.columns.drop([col])\n",
    "    \n",
    "    X_train = not_null[features]\n",
    "    y_train = not_null[col]\n",
    "    \n",
    "    X_pred = is_null[features]\n",
    "\n",
    "    model = HistGradientBoostingRegressor(random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = model.predict(X_pred)\n",
    "    predictions = np.round(predictions).astype('int64')\n",
    "    df_filled.loc[df_filled[col].isna(), col] = predictions\n",
    "    \n",
    "    print(f\"Filled {len(predictions)} rows in {col}\")\n",
    "\n",
    "# Restore categorical values back to original encoding\n",
    "df_filled[categorical_cols] = encoder.inverse_transform(df_filled[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_model['central_air'].cat.categories\n",
    "#df_model['basements'].cat.categories\n",
    "#df_model['type_heater'].cat.categories\n",
    "#df_model.groupby('basements')['sale_price'].median().sort_values()\n",
    "#df_model.groupby('type_heater')['sale_price'].median().sort_values()\n",
    "#df_model.groupby('view_type')['sale_price'].median().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn centeral_air into a bool\n",
    "df_filled['central_air'] = df_filled['central_air'].map({'Y': True, 'N': False})\n",
    "\n",
    "# map using grouped median values\n",
    "basement_scale = {\n",
    "    '0': 0,   \n",
    "    'D': 1,   \n",
    "    'C': 2,   \n",
    "    'B': 3,   \n",
    "    'A': 4,   \n",
    "    'H': 5,   \n",
    "    'E': 6,   \n",
    "    'F': 7,   \n",
    "    'G': 8,   \n",
    "}\n",
    "df_filled['basements'] = df_filled['basements'].map(basement_scale)\n",
    "\n",
    "# map using grouped median values\n",
    "type_heater_scale = {\n",
    "    'G': 0,   \n",
    "    'H': 1,   \n",
    "    'F': 2,\n",
    "    'E': 3,\n",
    "    'B': 4,   \n",
    "    'C': 5,   \n",
    "    'D': 6,   \n",
    "    'A': 7,   \n",
    "}\n",
    "df_filled['type_heater'] = df_filled['type_heater'].map(type_heater_scale)\n",
    "\n",
    "# map using grouped median values\n",
    "view_type_scale = {\n",
    "    '0': 0,   \n",
    "    'I': 1,   \n",
    "    'D': 2,\n",
    "    'C': 3,\n",
    "    'B': 4,\n",
    "    'A': 5,\n",
    "    'H': 6,   \n",
    "    'E': 7,   \n",
    "}\n",
    "df_filled['view_type'] = (\n",
    "    df_model['view_type']\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .replace({'nan': np.nan, 'None': np.nan, '<NA>': np.nan})\n",
    "    .map(view_type_scale)\n",
    ")\n",
    "\n",
    "df_filled['view_type'] = df_filled['view_type'].astype('Int64')\n",
    "# define condition scale\n",
    "valid_condition_values = {'1', '2', '3', '4', '5', '6', '7'}\n",
    "\n",
    "# clean both columns\n",
    "for col in ['exterior_condition', 'interior_condition']:\n",
    "    df_filled[col] = df_filled[col].astype(str).str.strip()\n",
    "    df_filled[col] = df_filled[col].where(df_filled[col].isin(valid_condition_values), np.nan)\n",
    "    df_filled[col] = pd.to_numeric(df_filled[col], errors='coerce').astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Filling missing value in column basements\n",
      "Filled 7140\n",
      "\n",
      " Filling missing value in column central_air\n",
      "Filled 7527\n",
      "\n",
      " Filling missing value in column type_heater\n",
      "Filled 6917\n",
      "\n",
      " Filling missing value in column exterior_condition\n",
      "Filled 960\n",
      "\n",
      " Filling missing value in column interior_condition\n",
      "Filled 959\n",
      "\n",
      " Filling missing value in column view_type\n",
      "Filled 502\n"
     ]
    }
   ],
   "source": [
    "# save dataframe to temp dataframe\n",
    "df_temp = df_filled.copy()\n",
    "\n",
    "# convert booleans to int for modeling\n",
    "bool_cols = df_temp.select_dtypes(include='bool').columns\n",
    "df_temp[bool_cols] = df_temp[bool_cols].astype(int)\n",
    "\n",
    "# list of columns to fill\n",
    "cols_to_fill = [\n",
    "    'basements', 'central_air', 'type_heater',\n",
    "    'exterior_condition', 'interior_condition',\n",
    "    'view_type'  # ← just add this here!\n",
    "]\n",
    "\n",
    "# loop through each column and fill with classification model\n",
    "for target_col in cols_to_fill:\n",
    "    print(f\"\\n Filling missing value in column {target_col}\")\n",
    "    \n",
    "    # drop target and label if present\n",
    "    predictors = df_temp.columns.drop([target_col, 'sale_price'])\n",
    "\n",
    "    # create encoder for predictors\n",
    "    encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    X_raw = df_temp[predictors].copy()\n",
    "\n",
    "    # fill missing values for categorical columns\n",
    "    cat_cols = X_raw.select_dtypes(include=['object', 'category']).columns\n",
    "    X_raw[cat_cols] = X_raw[cat_cols].fillna(\"Missing\")\n",
    "    X_raw[cat_cols] = encoder.fit_transform(X_raw[cat_cols].astype(str))\n",
    "\n",
    "    # split data for training and prediction\n",
    "    y = df_temp[target_col]\n",
    "    mask_known = y.notna()\n",
    "    mask_missing = ~mask_known\n",
    "\n",
    "    if mask_missing.sum() == 0:\n",
    "        print(f\"No missing values\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # train classifier\n",
    "        model = HistGradientBoostingClassifier(random_state=0)\n",
    "        model.fit(X_raw.loc[mask_known], y[mask_known].astype(float))\n",
    "\n",
    "        # predict and fill\n",
    "        preds = model.predict(X_raw.loc[mask_missing])\n",
    "        df_temp.loc[mask_missing, target_col] = preds\n",
    "\n",
    "        print(f\"Filled {mask_missing.sum()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Not filling {target_col}: {e}\")\n",
    "\n",
    "# copy to df_filled\n",
    "df_filled[cols_to_fill] = df_temp[cols_to_fill]\n",
    "df_filled['central_air'] = df_filled['central_air'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19998 entries, 0 to 19997\n",
      "Data columns (total 24 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   zip_code             19998 non-null  object \n",
      " 1   total_livable_area   19998 non-null  float64\n",
      " 2   total_area           19998 non-null  float64\n",
      " 3   number_of_bedrooms   19998 non-null  Int64  \n",
      " 4   number_of_bathrooms  19998 non-null  Int64  \n",
      " 5   number_stories       19998 non-null  Int64  \n",
      " 6   garage_spaces        19998 non-null  Int64  \n",
      " 7   basements            19998 non-null  float64\n",
      " 8   view_type            19998 non-null  Int64  \n",
      " 9   central_air          19998 non-null  bool   \n",
      " 10  type_heater          19998 non-null  float64\n",
      " 11  exterior_condition   19998 non-null  Int64  \n",
      " 12  interior_condition   19998 non-null  Int64  \n",
      " 13  sale_price           19998 non-null  Int64  \n",
      " 14  market_value         19998 non-null  float64\n",
      " 15  year_built           19998 non-null  Int64  \n",
      " 16  year_built_estimate  19998 non-null  object \n",
      " 17  has_basements        19998 non-null  bool   \n",
      " 18  has_central_air      19998 non-null  bool   \n",
      " 19  has_type_heater      19998 non-null  bool   \n",
      " 20  is_nominal_sale      19998 non-null  bool   \n",
      " 21  sale_year            19998 non-null  int64  \n",
      " 22  sale_month           19998 non-null  int64  \n",
      " 23  sale_day             19998 non-null  int64  \n",
      "dtypes: Int64(9), bool(5), float64(5), int64(3), object(2)\n",
      "memory usage: 5.2 MB\n"
     ]
    }
   ],
   "source": [
    "df_filled.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid rerunning code creating copy to clean\n",
    "df_cleaning = df_filled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow learning model to use date turning it into its own column\n",
    "df_cleaning['sale_date'] = pd.to_datetime({\n",
    "    'year': df_cleaning['sale_year'].astype('int'),\n",
    "    'month': df_cleaning['sale_month'].astype('int'),\n",
    "    'day': df_cleaning['sale_day'].astype('int')\n",
    "}, errors='coerce')\n",
    "df_cleaning.drop(columns=['sale_year', 'sale_month', 'sale_day'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = [\n",
    "    'zip_code',\n",
    "    'sale_date',\n",
    "\n",
    "    # property features\n",
    "    'view_scale',\n",
    "    'heater_scale',\n",
    "    'exterior_condition',\n",
    "    'interior_condition',\n",
    "    'central_air',\n",
    "    'basement_scale',\n",
    "    'garage_spaces',\n",
    "    'number_of_bedrooms',\n",
    "    'number_of_bathrooms',\n",
    "    'number_stories',\n",
    "    'total_livable_area',\n",
    "    'total_area',\n",
    "    'year_built',\n",
    "    'year_built_estimate',\n",
    "\n",
    "    # boolean flags\n",
    "    'has_basements',\n",
    "    'has_central_air',\n",
    "    'has_type_heater',\n",
    "    'is_nominal_sale',\n",
    "\n",
    "    # price-related\n",
    "    'market_value',\n",
    "    'sale_price'\n",
    "]\n",
    "\n",
    "df_cleaning['has_basements'] = df_cleaning['basements'].fillna(0).astype(float) > 0\n",
    "df_cleaning.rename(columns={\n",
    "    'view_type': 'view_scale',\n",
    "    'type_heater': 'heater_scale',\n",
    "    'basements': 'basement_scale'\n",
    "}, inplace=True)\n",
    "df_cleaned = df_cleaning[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19998 entries, 0 to 19997\n",
      "Data columns (total 22 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   zip_code             19998 non-null  object        \n",
      " 1   sale_date            19998 non-null  datetime64[ns]\n",
      " 2   view_scale           19998 non-null  Int64         \n",
      " 3   heater_scale         19998 non-null  float64       \n",
      " 4   exterior_condition   19998 non-null  Int64         \n",
      " 5   interior_condition   19998 non-null  Int64         \n",
      " 6   central_air          19998 non-null  bool          \n",
      " 7   basement_scale       19998 non-null  float64       \n",
      " 8   garage_spaces        19998 non-null  Int64         \n",
      " 9   number_of_bedrooms   19998 non-null  Int64         \n",
      " 10  number_of_bathrooms  19998 non-null  Int64         \n",
      " 11  number_stories       19998 non-null  Int64         \n",
      " 12  total_livable_area   19998 non-null  float64       \n",
      " 13  total_area           19998 non-null  float64       \n",
      " 14  year_built           19998 non-null  Int64         \n",
      " 15  year_built_estimate  19998 non-null  object        \n",
      " 16  has_basements        19998 non-null  bool          \n",
      " 17  has_central_air      19998 non-null  bool          \n",
      " 18  has_type_heater      19998 non-null  bool          \n",
      " 19  is_nominal_sale      19998 non-null  bool          \n",
      " 20  market_value         19998 non-null  float64       \n",
      " 21  sale_price           19998 non-null  Int64         \n",
      "dtypes: Int64(9), bool(5), datetime64[ns](1), float64(5), object(2)\n",
      "memory usage: 4.9 MB\n"
     ]
    }
   ],
   "source": [
    "#df_cleaned.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_csv(\"philly_property_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
