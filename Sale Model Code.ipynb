{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "#Jets adding\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import combined data from csv\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\grovenbm\\\\Documents\\\\oms_analytics\\\\CSE 6242\\\\Project\\\\Tests\\\\philly_final_dataset_Reduced.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['sale_price']\n",
    "data_Features = data.drop(columns=['sale_price','Est TOM in Days'])\n",
    "data_hot = data_Features\n",
    "data_hot = pd.get_dummies(data_hot, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data10_hot, y, test_size=0.3, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_hot, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Standardize full feature set for Elastic Net variable selection\n",
    "scaler_full = StandardScaler()\n",
    "X_train_scaled_full = scaler_full.fit_transform(X_train)\n",
    "X_test_scaled_full = scaler_full.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:\n",
      "Index(['zip_code', 'central_air', 'garage_spaces', 'number_of_bedrooms',\n",
      "       'number_of_bathrooms', 'number_stories', 'total_livable_area',\n",
      "       'total_area', 'year_built', 'has_basements', 'active_inventory',\n",
      "       'new_listings', 'pending_sales', 'homes_sold', 'sale_to_list_ratio',\n",
      "       'percent_above_list', 'avg_days_on_market', 'avg_list_price_per_sqft',\n",
      "       'avg_listed_price', 'avg_price_per_sqft', 'avg_price_sold'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Variable selection with Elastic Net\n",
    "elasticNet = ElasticNetCV(l1_ratio=0.5, cv=5)\n",
    "elasticNet.fit(X_train_scaled_full, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "coefficients = elasticNet.coef_\n",
    "selected_features = data_hot.columns[coefficients != 0]\n",
    "print(\"Selected features:\")\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------End of Variable Selection--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------------------------End of Variable Selection--------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "[-536867.07825505   74352.83834669 1013906.94758709 ... 1887590.41706514\n",
      "  114726.50446234  964439.23253535]\n",
      "RMSE:\n",
      "959831.7116652863\n",
      "R2:\n",
      "0.2727150065364611\n",
      "Coefficients:\n",
      "[-2.54615666e+03  1.78051550e+05  2.22946209e+05  3.51178029e+04\n",
      "  9.00308543e+04  6.43461597e+05  1.27498317e+01  1.16779265e-02\n",
      " -1.36256168e+02 -3.91394065e+05  9.02889870e+02 -4.97894032e+03\n",
      "  1.03990159e+04 -5.15106133e+03 -8.17391891e+05 -7.58625667e+04\n",
      " -1.22987216e+03  4.12535581e+02  3.08817598e-01  7.33931129e+02\n",
      " -6.71925879e-01]\n",
      "Intercept:\n",
      "48756421.45380745\n"
     ]
    }
   ],
   "source": [
    "#Instiantiate model\n",
    "LMmodel = LinearRegression()\n",
    "\n",
    "#fit model to training data. Using only selected features\n",
    "X_train_selected = X_train[selected_features]\n",
    "\n",
    "LMmodel.fit(X_train_selected, y_train)\n",
    "\n",
    "#predict on test data\n",
    "x_test_selected = X_test[selected_features]\n",
    "y_pred = LMmodel.predict(x_test_selected)\n",
    "\n",
    "print(\"Predictions:\")\n",
    "print(y_pred)\n",
    "\n",
    "#calculate RMSE and R2\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\")\n",
    "print(RMSE)\n",
    "print(\"R2:\")\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "print(R2)\n",
    "\n",
    "#Access coefficients\n",
    "coefficients = LMmodel.coef_\n",
    "print(\"Coefficients:\")\n",
    "print(coefficients)\n",
    "\n",
    "#Access intercept\n",
    "intercept = LMmodel.intercept_\n",
    "print(\"Intercept:\")\n",
    "print(intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress...\n",
      "Predictions:\n",
      "[ 212970.          133028.16357143  540709.9        ... 3009170.16\n",
      "  171568.88        460658.62      ]\n",
      "RMSE:\n",
      "566252.6303970212\n",
      "R2:\n",
      "0.7468750803573763\n",
      "Feature Importances:\n",
      "[9.27631290e-03 9.80639952e-03 7.33431192e-03 1.56383374e-02\n",
      " 2.14114143e-02 2.84773444e-01 4.51487731e-01 5.07960405e-02\n",
      " 3.05241380e-02 9.59154909e-05 7.20936429e-03 1.59179289e-02\n",
      " 1.01517165e-02 1.56003956e-02 1.47300594e-02 1.07202496e-02\n",
      " 9.74269540e-03 0.00000000e+00 6.86338955e-03 8.71805766e-03\n",
      " 6.86706236e-03 8.40872584e-03 3.92630965e-03]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "#Instantiating Random Forest Model\n",
    "RFmodel = RandomForestRegressor(n_estimators=50, random_state=1,n_jobs=-1 ,verbose=1)\n",
    "\n",
    "#RF model fit\n",
    "RFmodel.fit(X_train, y_train)\n",
    "\n",
    "#Sanity check\n",
    "print(\"Progress...\")\n",
    "\n",
    "#Predicting on test data\n",
    "y_pred_RF = RFmodel.predict(X_test)\n",
    "print(\"Predictions:\")\n",
    "print(y_pred_RF)\n",
    "\n",
    "# Calculate RMSE and R2\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, y_pred_RF))\n",
    "print(\"RMSE:\")\n",
    "print(RMSE)\n",
    "print(\"R2:\")\n",
    "R2 = r2_score(y_test, y_pred_RF)\n",
    "print(R2)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Access feature importances (since Random Forest models provide feature importance)\n",
    "print(\"Feature Importances:\")\n",
    "feature_importance = pd.Series(RFmodel.feature_importances_, index=feature_names)\n",
    "feature_importance = feature_importance.sort_values(ascending=False)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "[ 186185.3796489   154549.64214761  503762.22204732 ... 4570769.83245907\n",
      "  172904.81040553  532677.65280899]\n",
      "RMSE (Gradient Boosting): 577112.8228512147\n",
      "R² (Gradient Boosting): 0.7370725764255591\n",
      "Feature Importances (Gradient Boosting):\n",
      "[1.12684896e-02 6.55851414e-03 7.64903879e-03 7.19577463e-03\n",
      " 4.86027070e-02 3.32697856e-01 3.83818375e-01 6.32154839e-02\n",
      " 2.06151660e-02 4.62885110e-05 2.93880273e-03 5.77268052e-03\n",
      " 3.85696862e-03 3.68439183e-03 9.26540202e-03 9.98097445e-03\n",
      " 3.01570027e-02 0.00000000e+00 1.68408292e-03 3.22831284e-02\n",
      " 4.47526621e-03 7.01341834e-03 7.22018792e-03]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Gradient Boosting model\n",
    "\n",
    "'''\n",
    "GBmodel = GradientBoostingRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.15,\n",
    "    max_depth=4,\n",
    "    random_state=1,\n",
    "    verbose=1\n",
    ")\n",
    "'''\n",
    "GBmodel = GradientBoostingRegressor(\n",
    "    subsample= 1.0, n_estimators= 500,\n",
    "    min_samples_split= 2, min_samples_leaf= 1,\n",
    "    max_features= None, max_depth= 4, learning_rate= 0.15\n",
    ")\n",
    "\n",
    "# Fit the model on untransformed target\n",
    "GBmodel.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_GB = GBmodel.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "RMSE_GB = np.sqrt(mean_squared_error(y_test, y_pred_GB))\n",
    "R2_GB = r2_score(y_test, y_pred_GB)\n",
    "\n",
    "print(\"Predictions:\")\n",
    "print(y_pred_GB)\n",
    "print(\"RMSE (Gradient Boosting):\", RMSE_GB)\n",
    "print(\"R² (Gradient Boosting):\", R2_GB)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Access feature importances\n",
    "print(\"Feature Importances:\")\n",
    "feature_importance = pd.Series(GBmodel.feature_importances_, index=feature_names)\n",
    "feature_importance = feature_importance.sort_values(ascending=False)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best Parameters Found:\n",
      "{'subsample': 1.0, 'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 3, 'learning_rate': 0.1}\n",
      "Best Cross-Validated R² Score:\n",
      "0.5940243816784413\n",
      "\n",
      "Test Set Evaluation\n",
      "RMSE: 686769.4148392775\n",
      "R²: 0.6276628851536792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['modelSale.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameter distribution\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Instantiate base model\n",
    "gbr = GradientBoostingRegressor(random_state=1)\n",
    "\n",
    "# Set up randomized search\n",
    "rand_search = RandomizedSearchCV(\n",
    "    estimator=gbr,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,               # Number of random combinations to try\n",
    "    scoring='r2',            # Optimize for R² score\n",
    "    cv=3,                    # 3-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1,               # Use all available cores\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit to training data\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best Parameters Found:\")\n",
    "print(rand_search.best_params_)\n",
    "print(\"Best Cross-Validated R² Score:\")\n",
    "print(rand_search.best_score_)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_gbr = rand_search.best_estimator_\n",
    "y_pred_best = best_gbr.predict(X_test)\n",
    "\n",
    "rmse_best = np.sqrt(mean_squared_error(y_test, y_pred_best))\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(\"\\nTest Set Evaluation\")\n",
    "print(\"RMSE:\", rmse_best)\n",
    "print(\"R²:\", r2_best)\n",
    "\n",
    "#with open(\"modelSale.pkl\", \"wb\") as f:\n",
    "    #import pickle\n",
    "joblib.dump(best_gbr, 'modelSale.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
